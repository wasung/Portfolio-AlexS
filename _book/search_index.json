[["index.html", "COVID-19 Report 1 Introduction 1.1 Contact", " COVID-19 Report 1 Introduction welcome to my Data Science for Biology portfolio! My name is Alex Sung, and I am a life scientist with a interest in applying data science techniques to solve biological problems.I am currently pursuing a Bachelor’s degree in Life Science with a specialization in Biomolecular Research at HU University of Applied Sciences in Utrecht, the Netherlands. Additionally, I am minoring in Data Science for Biology, which has allowed me to explore the intersection of life sciences and computational methods. The course is created by … This github page will serve as my portfolio as data scientist. 1.1 Contact email: wkasung@gmail.com GitHub: https://github.com/wasung "],["curriculum-vitae-wing-kien-alex-sung.html", "2 Curriculum Vitae Wing-kien Alex Sung Education Work Experience Activities Additional Skills", " 2 Curriculum Vitae Wing-kien Alex Sung Address: De Kriek 29, Vleuten E-mail: wkasung@gmail.com Phone: +31 6 52220022 Date of Birth: 24 September 2000 Nationality: Dutch Education 2020 – Present HU University of Applied Sciences, Utrecht, the Netherlands BSc Life Science Biomolecular Research specialisation Minor: Data Science for Biology Honours Programme Extra year due to sports injury 2012 – 2018 Niftarlake College, Maarssen, the Netherlands General Secondary Education (upper-intermediate level) Work Experience Jul 2024 – Present Cell and Gene Therapy Facility Intern, Prinses Maxima Centrum voor Kinderoncologie, Utrecht Environmental monitoring and PQ of cleanroom under ISO and GMP guidelines. Oct 2023 – Present Founder, Kokoro Skincare, Rotterdam Founded Kokoro Skincare, managing strategy, compliance, and marketing. Expanded to Germany and Belgium, building a trusted Japanese beauty e-commerce brand. Dec 2023 – Present Freelance Business Analyst, Remote Streamlined reporting processes and translated data into user-friendly reports. Supported stakeholders in data-driven decision-making. Feb 2022 – Nov 2022 Laboratory Technician, Saltro BV, Utrecht Executed precise analysis of COVID-19 samples using rt-qPCR techniques. Jul 2021 – Dec 2021 Laboratory Technician, Eurofins, Barneveld Conducted soil and water pretreatment for ICP-MS analysis. Measured diverse environmental parameters. Activities Sep 2023 – Present Head of Partnership Committee, CSA-EUR, Rotterdam Sep 2023 – Jun 2024 Active Member, Delft Committee, CSA-EUR, Rotterdam Jan 2020 – Present Sponsored Badminton Player, Victor Europe GmbH, Germany Additional Skills Languages: English (Professional), Dutch (native) Software &amp; Tools: Microsoft Office (Outlook, Word, Excel, PowerPoint) Power BI (good command) IBM SPSS Statistics (fair command) RStudio (fair command) Driving License: Full Hobbies: Fitness, Badminton, Reading, Photography "],["looking-ahead.html", "3 Looking Ahead Professional Development", " 3 Looking Ahead My academic journey began with a fascination for molecular biology, but over time, I’ve found myself drawn to a broader vision of how I want to contribute to the life sciences sector. Rather than remaining solely in the laboratory, I’m increasingly motivated by the idea of playing a more strategic role—where science, data, and business come together to create real-world impact. I want to be involved in designing solutions, informing decisions, and shaping the direction of healthcare innovations, particularly in fields where science meets patient outcomes and commercial viability. To support this shift, I chose to pursue the Data Science for Biology minor alongside my Bachelor’s in Life Sciences. This combination reflects my desire to bridge hard scientific knowledge with analytical and business-oriented thinking. I believe that fluency in data—whether it’s understanding experimental design, visualizing trends, or interpreting statistical outcomes—is a crucial skill in almost any role across life sciences, biotech, and healthcare consulting. From my perspective, knowing how to work with data empowers you to be a decision-maker. While my initial goal was to find an internship specifically focused on data science or sequencing, I ultimately accepted a position at a cell and gene therapy facility—an opportunity that has proven both challenging and eye-opening. Working in this highly regulated environment has taught me a great deal about Good Manufacturing Practice (GMP), cleanroom operations, and contamination control strategies. I’ve been involved in environmental monitoring and performance qualification (PQ) processes, all of which have given me a deeper appreciation for the complexities of translating research into safe therapies. While this internship doesn’t involve coding or computational analysis directly, it’s reinforcing my understanding of the operational and regulatory backbone of modern therapeutics, something I consider just as important. Looking further ahead, I see strategy consulting as the most likely next step in my career. I’m especially interested in specializing within the healthcare and life sciences sector, where I can apply my background to strategic challenges in pharma, biotech, or health tech. However, I remain open and excited to explore other industries as well, particularly during the early stages of my consulting journey. I value the opportunity to learn across a wide range of business contexts and expand my thinking beyond my academic background. To prepare for this next phase, I’ve applied to the pre-master programme at Erasmus University Rotterdam, with the goal of continuing on to a Master in Management. This academic step will allow me to deepen my understanding of business, strategy, and organizational dynamics, and will complement the technical and scientific knowledge I’ve built during my Life Sciences degree. In short, I’m still evolving as a professional, but I’m actively shaping my own trajectory. I’m seeking out the tools, experiences, and mindsets that will help me grow—and I’m committed to building a career that blends the depth of science with the breadth of strategy. Professional Development As part of the Data Science for Biology course, we are allocated time to independently explore a bioinformatics-related topic of our choice. I’ve chosen to focus on variant calling, specifically using the Variant Tools package available via Conda, as this aligns with my interest in genomics and data-driven biological insights. I plan to apply these skills in a self-directed project using a publicly available dataset, allowing me to gain hands-on experience beyond the classroom or lab setting. Outside of this academic framework, I’m continuing to build up my data skills independently. I’ve been exploring tools like Power BI to strengthen my business intelligence capabilities, and I’m actively learning more about Python for data analysis. I believe that by combining my scientific background with growing analytical and technical expertise, I’ll be well-positioned for cross-disciplinary roles — whether in consulting, biotech strategy, or data-driven innovation within the healthcare sector. "],["variant-analysis-tools.html", "4 Variant Analysis tools 4.1 Summary personal Timeline and Motivation 4.2 Background 4.3 Discussion 4.4 Conclusion and Recommendations", " 4 Variant Analysis tools 4.1 Summary personal Timeline and Motivation My initial plan was to perform a comprehensive comparison between vcfR, VariantAnnotation, and VariantTools. However, this proved impractical due to incompatible input requirements (VCF vs BAM). I dropped VariantTools from the initial comparison and refocused on filtering using vcfR and VariantAnnotation. My large VCF dataset crashed vcfR, while VariantAnnotation managed to process it. I attempted smaller datasets but faced issues with missing or poor quality scores. I experimented with deepSNV and mitoClone2 for variant calling but encountered persistent file access errors. Revisited VariantTools for variant calling but was blocked by gmapR/GSNAP issues on Windows. Pivoted to using the VariantAnnotation tutorial dataset (chromosome 22) and compared it with vcfR for variant filtering. Throughout this process, my choices were guided by tool limitations, computational feasibility, and my evolving understanding of each package’s strengths. 4.2 Background Variant calling is a crucial step in genomic analysis that involves identifying differences in DNA sequence compared to a reference genome. These variants can include single nucleotide polymorphisms (SNPs), insertions, deletions, and more. Accurate variant calling is essential for downstream applications such as disease gene discovery, pharmacogenomics, and population genetics. Several R packages are available for handling variant data, each with its own strengths and limitations: VariantAnnotation: A comprehensive Bioconductor package that provides functionality for reading, annotating, and filtering VCF files. It’s particularly strong in structured data handling and integration with annotation resources. vcfR: Designed for fast and interactive VCF file exploration, especially useful for lightweight operations, visualization, and subsetting. VariantTools: An end-to-end framework for variant calling and filtering directly from BAM files, integrated with Bioconductor’s genomic data structures. deepSNV: A package tailored to identifying low-frequency variants, particularly useful for ultra-deep sequencing data. mitoClone2: A downstream tool based on deepSNV, focused on mitochondrial heteroplasmy and clonal lineage analysis. I initially set out to perform a three-way comparison between the R packages VariantAnnotation, vcfR, and VariantTools. My goal was to compare how these tools handled variant filtering, annotation, and representation. However, I quickly discovered that the input formats and assumptions across the packages were not aligned. VariantTools expects BAM files, while vcfR and VariantAnnotation work directly with VCFs. Due to this, I explored deepSNV. Unfortunately, this failed due to file access issues when trying to extract base counts from BAM files: library(deepSNV) bam_list &lt;- list(H1993 = &quot;H1993.bam&quot;) tp53_region &lt;- GenomicRanges::GRanges(&quot;chr17&quot;, IRanges(7565097, 7590856)) counts &lt;- baseCountsFromBamList(bamfiles = bam_list, sites = tp53_region) This motivated me to try mitoClone2, which builds on deepSNV, but I encountered the same BAM access issues: library(mitoClone2) bam_list &lt;- list(H1993 = &quot;H1993.bam&quot;) tp53_region &lt;- GenomicRanges::GRanges(&quot;chr17&quot;, IRanges(7565097, 7590856)) counts &lt;- baseCountsFromBamList(bamfiles = bam_list, sites = tp53_region) Since both packages depend heavily on deepSNV’s functionality and required very specific BAM setups, I dropped them. However, I recognize that deepSNV is suitable for detecting low-frequency variants in ultra-deep sequencing, and mitoClone2 would be well-suited for mitochondrial DNA analysis and clonal structure inference in single-cell data. Simultaneously, I explored using VariantTools again for variant calling. But I discovered that subsetting data with this package depends on gmapR, which in turn relies on GSNAP. This made it incompatible with Windows, making my plan to use a smaller subset of data infeasible within my current setup. Given the challenges with variant calling, I returned to my original idea of variant filtering. I aimed to compare vcfR and VariantAnnotation more thoroughly. I started with a large VCF file. VariantAnnotation could process it, but vcfR repeatedly crashed my system due to memory limitations: library(VariantAnnotation) vcf_obj &lt;- readVcf(&quot;large_sample.vcf.gz&quot;, &quot;hg38&quot;) rowRanges(vcf_obj) library(vcfR) vcf &lt;- read.vcfR(&quot;large_sample.vcf.gz&quot;) # Crashed system To deal with this, I shifted to a smaller dataset. Unfortunately, I then found that the data either had no QUAL scores or all values were below 30, making them unsuitable for quality-based filtering. I decided to pivot again to well-characterized, smaller datasets—specifically, those based on chromosomes 20 or 22, which are often used in tutorials due to their manageable size and representative features. I initially downloaded a chromosome 22 dataset, but it still proved too large. Eventually, I found that VariantAnnotation includes a built-in example dataset based on chromosome 22. This dataset allowed me to continue my comparison without crashing or compatibility issues. library(VariantAnnotation) fl &lt;- system.file(&quot;extdata&quot;, &quot;chr22.vcf.gz&quot;, package = &quot;VariantAnnotation&quot;) vcf &lt;- readVcf(fl, &quot;hg19&quot;) summary(vcf) This final adjustment allowed me to complete my comparative analysis between vcfR and VariantAnnotation effectively, using realistic and tractable data. 4.3 Discussion This project revealed both the power and the constraints of variant analysis tools in R. While my initial goals were ambitious, real-world file sizes, system constraints, and software compatibility forced me to adapt repeatedly. 4.3.1 What Went Well Successfully explored multiple R packages and understood their input/output structures. Managed to compare and visualize variant calls using GenomicRanges, even without full pipeline compatibility. Gained valuable insights into what tools are realistic to run on a typical local setup. 4.3.2 What Didn’t Work deepSNV and mitoClone2 failed due to BAM access issues and setup requirements. VariantTools’ reliance on gmapR made it unusable on Windows. Large datasets were infeasible to process with vcfR due to memory limits. 4.4 Conclusion and Recommendations Based on my experience: Use vcfR for quick, small-scale variant filtering and visualization. It’s great for exploratory analysis but not built for large files. Use VariantAnnotation for structured, reproducible workflows and integration with annotation databases. It handles large files more gracefully and provides robust filtering tools. Avoid VariantTools on Windows unless working in a Unix-based environment with GSNAP installed. Avoid deepSNV and mitoClone2 unless you have a very specific need for ultra-deep sequencing or mitochondrial variant analysis and your environment is set up accordingly. This project has been a challenging but rewarding exploration of the practicalities behind variant analysis in R. It highlighted the importance of choosing tools that align with both data and computing resources. "],["guerilla-analytics.html", "5 Guerilla Analytics 5.1 The focus is on organizing a project (RNAseq &amp; metagenomics analysis)", " 5 Guerilla Analytics The goal is to apply the Guerrilla Analytics framework to structure and document a project in a reproducible, collaborative, and future-proof way. 5.1 The focus is on organizing a project (RNAseq &amp; metagenomics analysis) 5.1.1 1. Reorganize Your Project Locate RStudio project folder used for the DAUR-II assignments. Download your work without the heavy data files Restructure the folder according to the Guerrilla Analytics folder principles 5.1.1.1 Data folders should contain: Only a README.txt file The README.txt should include: Description of the dataset Data format Where the data is stored (path or location) Any preprocessing steps or notes 5.1.2 2. Apply to Your RNAseq and Metagenomics Work You previously worked with: 3 RNAseq datasets One of them was the exam project 2 Metagenomics datasets For each dataset: - Create a modular folder (e.g., Data001, Data002, etc.) - Add a README.txt inside each module - Add any import or checksum scripts to a supporting/ subfolder 5.1.3 3. Use the {fs} Package to Generate a Folder Tree Screenshot To showcase your new project structure: library(fs) ## Warning: package &#39;fs&#39; was built under R version 4.4.3 # Print your current directory tree (recursively) dir_tree(&quot;Opdracht 5 - Guerilla analytics&quot;, recurse = TRUE) ## Opdracht 5 - Guerilla analytics ## ├── 01_raw_data ## │ ├── sample1_R1.fastq ## │ └── sample1_R2.fastq ## ├── 02_data ## │ └── sample1_aligned.bam ## ├── 03_analysis ## │ ├── 01_import_and_clean.R ## │ ├── 02_analysis.R ## │ └── 03_visualizations.R ## ├── 04_outputs ## │ ├── figures ## │ ├── reports ## │ └── tables ## └── README.md "],["c.elegans-plate-experiment.html", "6 C.elegans Plate Experiment 6.1 Exploring the Excel Dataset Structure 6.2 Importing the Dataset into R 6.3 Checking and Correcting Data Types 6.4 Visualizing Raw Data: Scatterplot 6.5 Fixing Axis Label Issues in ggplot 6.6 Identifying Positive Controls 6.7 Identifying Negative Controls 6.8 Designing a Statistical Analysis Strategy 6.9 Normalizing Data Using the Control Group 6.10 Why Normalize?", " 6 C.elegans Plate Experiment 6.1 Exploring the Excel Dataset Structure “Review the following Excel file in ./Opdracht 4 - Reproducible Science/4a - CELIQ/CE.LIQ.FLOW.062_Tidydata.xlsx…” The Parameters tab is unclear — it’s difficult to interpret what each column means. The Raw Data column lacks explanation, and the purpose of the coloring (particularly the long pink section) is not described. Other tabs are even more confusing due to minimal labeling and inconsistent formatting. 6.2 Importing the Dataset into R “Open the file in R using the {readxl} package.” library(here) library(readxl) library(tidyverse) # Import data CElegans_data &lt;- read_excel( here::here(&quot;Opdracht 4 - Reproducible Science&quot;, &quot;4a - CELIQ&quot;, &quot;CE.LIQ.FLOW.062_Tidydata.xlsx&quot;) ) # Preview head(CElegans_data) ## # A tibble: 6 × 34 ## plateRow plateColumn vialNr dropCode expType expReplicate expName ## &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 NA NA 1 a experiment 3 CE.LIQ.FLOW.062 ## 2 NA NA 1 b experiment 3 CE.LIQ.FLOW.062 ## 3 NA NA 1 c experiment 3 CE.LIQ.FLOW.062 ## 4 NA NA 1 d experiment 3 CE.LIQ.FLOW.062 ## 5 NA NA 1 e experiment 3 CE.LIQ.FLOW.062 ## 6 NA NA 2 a experiment 3 CE.LIQ.FLOW.062 ## # ℹ 27 more variables: expDate &lt;dttm&gt;, expResearcher &lt;chr&gt;, expTime &lt;dbl&gt;, ## # expUnit &lt;chr&gt;, expVolumeCounted &lt;dbl&gt;, RawData &lt;dbl&gt;, compCASRN &lt;chr&gt;, ## # compName &lt;chr&gt;, compConcentration &lt;chr&gt;, compUnit &lt;chr&gt;, ## # compDelivery &lt;chr&gt;, compVehicle &lt;chr&gt;, elegansStrain &lt;chr&gt;, ## # elegansInput &lt;dbl&gt;, bacterialStrain &lt;chr&gt;, bacterialTreatment &lt;chr&gt;, ## # bacterialOD600 &lt;dbl&gt;, bacterialConcX &lt;dbl&gt;, bacterialVolume &lt;dbl&gt;, ## # bacterialVolUnit &lt;chr&gt;, incubationVial &lt;chr&gt;, incubationVolume &lt;dbl&gt;, … 6.3 Checking and Correcting Data Types compConcentration was imported as character and was converted to numeric. compName and expType were converted to factors to allow proper grouping and visualization. # Inspect column types str(CElegans_data %&gt;% select(RawData, compName, compConcentration)) ## tibble [360 × 3] (S3: tbl_df/tbl/data.frame) ## $ RawData : num [1:360] 44 37 45 47 41 35 41 36 40 38 ... ## $ compName : chr [1:360] &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; ... ## $ compConcentration: chr [1:360] &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; ... # Convert data types as needed CElegans_data$compName &lt;- factor(CElegans_data$compName, levels = unique(CElegans_data$compName)) CElegans_data$expType &lt;- factor(CElegans_data$expType, levels = unique(CElegans_data$expType)) CElegans_data$compConcentration &lt;- parse_number(CElegans_data$compConcentration) # Confirm conversion str(CElegans_data %&gt;% select(RawData, compName, compConcentration, expType)) ## tibble [360 × 4] (S3: tbl_df/tbl/data.frame) ## $ RawData : num [1:360] 44 37 45 47 41 35 41 36 40 38 ... ## $ compName : Factor w/ 5 levels &quot;2,6-diisopropylnaphthalene&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ compConcentration: num [1:360] 4.99 4.99 4.99 4.99 4.99 4.99 4.99 4.99 4.99 4.99 ... ## $ expType : Factor w/ 4 levels &quot;experiment&quot;,&quot;controlPositive&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... 6.4 Visualizing Raw Data: Scatterplot library(ggplot2) library(tidyverse) # Plotting the scatterplot with dynamic shape assignment ggplot(CElegans_data, aes(x = log10(compConcentration), y = RawData)) + geom_point( aes(color = compName, shape = expType), size = 1.5, alpha = 0.8, position = position_jitter(width = 0.15) ) + labs( title = &quot;C. elegans Response by Compound and Concentration&quot;, caption = &quot;Raw data colored by compound, shaped by experiment type&quot;, x = &quot;log10(Compound Concentration) [nM]&quot;, y = &quot;Raw Data (counts)&quot; ) + scale_color_brewer(palette = &quot;Dark2&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) ## Warning: Removed 5 rows containing missing values or values outside the scale ## range (`geom_point()`). 6.5 Fixing Axis Label Issues in ggplot The compConcentration column was originally imported as a character variable, so ggplot2 treated it as a categorical (discrete) variable. This led to disorganized and overlapping axis labels. After converting it to numeric and applying log10(), the axis behaved as continuous, solving the issue. 6.6 Identifying Positive Controls The positive control for this experiments is controlPositive. 6.7 Identifying Negative Controls The negative control for this experiment is controlNegative. 6.8 Designing a Statistical Analysis Strategy Import and clean the dataset Convert character columns to numeric or factor types Visualize raw data for trends by concentration and compound Normalize RawData against the mean of the controlNegative group Re-plot normalized data to observe relative trends Check normality using Shapiro-Wilk tests Run ANOVA to detect significant differences across groups Apply post hoc tests if ANOVA is significant (e.g., Tukey HSD) Fit dose-response models to estimate IC50 values Compare confidence intervals between IC50 estimates Interpret results for biological and statistical significance 6.9 Normalizing Data Using the Control Group “Normalize the data for the controlNegative in such a way that the mean value for controlNegative is exactly equal to 1 and that all other values are expressed as a fraction thereof. Rerun your graphs with the normalized data.” # Calculate the mean for controlNegative neg_ctrl &lt;- CElegans_data %&gt;% filter(expType == &quot;controlNegative&quot;) neg_mean &lt;- mean(neg_ctrl$RawData) # Normalize the RawData CElegans_data &lt;- CElegans_data %&gt;% mutate(Normalized = RawData / neg_mean) # Preview normalized data head(CElegans_data %&gt;% select(compName, expType, compConcentration, RawData, Normalized)) ## # A tibble: 6 × 5 ## compName expType compConcentration RawData Normalized ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2,6-diisopropylnaphthalene experiment 4.99 44 0.512 ## 2 2,6-diisopropylnaphthalene experiment 4.99 37 0.431 ## 3 2,6-diisopropylnaphthalene experiment 4.99 45 0.524 ## 4 2,6-diisopropylnaphthalene experiment 4.99 47 0.547 ## 5 2,6-diisopropylnaphthalene experiment 4.99 41 0.477 ## 6 2,6-diisopropylnaphthalene experiment 4.99 35 0.407 ggplot(CElegans_data, aes(x = log10(compConcentration), y = Normalized)) + geom_point( aes(color = compName, shape = expType), size = 1.5, alpha = 0.8, position = position_jitter(width = 0.15) ) + labs( title = &quot;Normalized C. elegans Response&quot;, caption = &quot;Data normalized to controlNegative (mean = 1)&quot;, x = &quot;log10(Compound Concentration) [nM]&quot;, y = &quot;Normalized Raw Data&quot; ) + scale_color_brewer(palette = &quot;Dark2&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) ## Warning: Removed 5 rows containing missing values or values outside the scale ## range (`geom_point()`). 6.10 Why Normalize? This normalization allows for clearer comparison of relative differences between conditions. By setting the control to 1, the effect size of each treatment becomes easier to interpret. "],["reproducable-research-part-1.html", "7 Reproducable research part 1 7.1 Heterologous prime-boost immunisation with mRNA- and AdC68-based 2019-nCoV variant vaccines induces broad-spectrum immune responses in mice 7.2 Estimating the effects of non-pharmaceutical interventions on COVID-19 in Europe", " 7 Reproducable research part 1 7.1 Heterologous prime-boost immunisation with mRNA- and AdC68-based 2019-nCoV variant vaccines induces broad-spectrum immune responses in mice Xingxing Li, Jingjing Liu, Wenjuan Li, Qinhua Peng, Miao Li, Zhifang Ying, Zelun Zhang, Xinyu Liu, Xiaohong Wu, Danhua Zhao, Lihong Yang, Shouchun Cao, Yanqiu Huang, Leitai Shi, Hongshan Xu, Yunpeng Wang, Guangzhi Yue, Yue Suo, Jianhui Nie, Weijin Huang, Jia Li, * and Yuhua Li. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10050358/ (add reference later) Add research question Add summary methode en resultaten #Reproducable research part 2 7.1.1 Study purpose There was no concise statement in the introduction of the article, that established the reason the research was conducted. 7.1.2 Study location The study location has been mentioned in the methods, it was conducted at National institute for food and drug control (NIFDC). 7.1.3 Ethics statement There is a small ethics statement on handling of the animals and a small section on conflict of interest, this states there have been no conflicts with any other party. 7.1.4 Funding statement There is no section on fundings, however there is a section on acknowledgements. Here 2 companies are acknowledged for the provision of vaccines, it is rather unclear if these were provided for free or bought. 7.1.5 Data availability statement and location There is a small section where supplementary materials can be accessed. THere is a download link to the ‘data sheet’. The sheet is a word doc with the processed data in figures in a doc file. Access to raw data would be better to have. It does however mention that you can inquire for more data but it requires you to contact the authors but, there is no author contact info available. Furthermore no code was used for this research. #Reproducable research b part 1 Since no code was used I decided to reproduce another article which was this the following: 7.2 Estimating the effects of non-pharmaceutical interventions on COVID-19 in Europe (https://www.nature.com/articles/s41586-020-2405-7) The paper has R code shared in the project environment and has clear instructions how to reproduce the data from the paper. (Describe the code:) The script runs smoohtly after installing all packages. I got the code from : https://github.com/ImperialCollegeLondon/covid19model.git It clearly states version 7 was used for the Nature paper so I used that one. For this base-nature.r script was used. On a scale from 1-5 I would rate this paper a 5 in how easy it was to reproduce. I could import the all the scripts from their github and rerun their data through the scripts the used. library(rstan) library(data.table) library(lubridate) library(gdata) library(dplyr) library(tidyr) library(EnvStats) library(optparse) library(stringr) library(bayesplot) library(matrixStats) library(scales) library(gridExtra) library(ggpubr) library(cowplot) library(ggplot2) library(abind) source(&#39;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/scripts/process-covariates.r&#39;) # Commandline options and parsing parser &lt;- OptionParser() parser &lt;- add_option(parser, c(&quot;-D&quot;, &quot;--debug&quot;), action=&quot;store_true&quot;, help=&quot;Perform a debug run of the model&quot;) parser &lt;- add_option(parser, c(&quot;-F&quot;, &quot;--full&quot;), action=&quot;store_true&quot;, help=&quot;Perform a full run of the model&quot;) cmdoptions &lt;- parse_args(parser, args = commandArgs(trailingOnly = TRUE), positional_arguments = TRUE) # Default run parameters for the model if(is.null(cmdoptions$options$debug)) { DEBUG = Sys.getenv(&quot;DEBUG&quot;) == &quot;TRUE&quot; } else { DEBUG = cmdoptions$options$debug } # Sys.setenv(FULL = &quot;TRUE&quot;) if(is.null(cmdoptions$options$full)) { FULL = Sys.getenv(&quot;FULL&quot;) == &quot;TRUE&quot; } else { FULL = cmdoptions$options$full } if(DEBUG &amp;&amp; FULL) { stop(&quot;Setting both debug and full run modes at once is invalid&quot;) } if(length(cmdoptions$args) == 0) { StanModel = &#39;base-nature&#39; } else { StanModel = cmdoptions$args[1] } print(sprintf(&quot;Running %s&quot;,StanModel)) if(DEBUG) { print(&quot;Running in DEBUG mode&quot;) } else if (FULL) { print(&quot;Running in FULL mode&quot;) } cat(sprintf(&quot;Running:\\nStanModel = %s\\nDebug: %s\\n&quot;, StanModel,DEBUG)) # Read which countires to use countries &lt;- readRDS(&#39;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/regions.rds&#39;) # Read deaths data for regions d &lt;- readRDS(&#39;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/COVID-19-up-to-date.rds&#39;) # Read IFR and pop by country ifr.by.country &lt;- readRDS(&#39;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/popt-ifr.rds&#39;) # Read interventions interventions &lt;- readRDS(&#39;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/interventions.rds&#39;) forecast &lt;- 0 # increase to get correct number of days to simulate # Maximum number of days to simulate N2 &lt;- (max(d$DateRep) - min(d$DateRep) + 1 + forecast)[[1]] processed_data &lt;- process_covariates(countries = countries, interventions = interventions, d = d , ifr.by.country = ifr.by.country, N2 = N2) stan_data = processed_data$stan_data dates = processed_data$dates deaths_by_country = processed_data$deaths_by_country reported_cases = processed_data$reported_cases options(mc.cores = parallel::detectCores()) rstan_options(auto_write = TRUE) m = stan_model(paste0(&#39;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/&#39;,StanModel,&#39;.stan&#39;)) if(DEBUG) { fit = sampling(m,data=stan_data,iter=40,warmup=20,chains=2) } else if (FULL) { fit = sampling(m,data=stan_data,iter=1800,warmup=1000,chains=5,thin=1,control = list(adapt_delta = 0.99, max_treedepth = 20)) } else { fit = sampling(m,data=stan_data,iter=600,warmup=300,chains=4,thin=1,control = list(adapt_delta = 0.95, max_treedepth = 10)) } out = rstan::extract(fit) prediction = out$prediction estimated.deaths = out$E_deaths estimated.deaths.cf = out$E_deaths0 # Use fixed JOBID for reproducible filename (you can change &#39;2048690&#39; to any label you want) JOBID &lt;- &quot;2048690&quot; print(sprintf(&quot;Jobid = %s&quot;,JOBID)) countries &lt;- countries$Regions save(fit,prediction,dates,reported_cases,deaths_by_country,countries,estimated.deaths,estimated.deaths.cf,stan_data, file=paste0(&#39;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/Results/&#39;,StanModel,&#39;-&#39;,JOBID,&#39;-stanfit.Rdata&#39;)) library(bayesplot) filename &lt;- paste0(StanModel,&#39;-&#39;,JOBID) print(&#39;Generating mu, rt plots&#39;) mu = (as.matrix(out$mu)) colnames(mu) = countries g = (mcmc_intervals(mu,prob = .9)) ggsave(sprintf(&quot;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/%s-mu.png&quot;,filename),g,width=4,height=6) tmp = lapply(1:length(countries), function(i) (out$Rt_adj[,stan_data$N[i],i])) Rt_adj = do.call(cbind,tmp) colnames(Rt_adj) = countries g = (mcmc_intervals(Rt_adj,prob = .9)) ggsave(sprintf(&quot;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/figures/%s-final-rt.png&quot;,filename),g,width=4,height=6) print(&quot;Generate 3-panel plots&quot;) source(&quot;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/scripts/plot-3-panel.r&quot;) make_three_panel_plot(filename) print(&#39;Covars plots&#39;) source(&#39;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/scripts/covariate-size-effects.r&#39;) plot_covars(filename) print(&#39;Making table&#39;) source(&#39;~/Portfolio-AlexS/Opdracht 4 - Reproducible Science/4b - Nature article files/scripts/make-table.r&#39;) make_table(filename) "],["relational-databases.html", "8 Relational databases", " 8 Relational databases Passed the SQL assesment in Period D of academic year of 2023/2024 "],["genetrackr.html", "9 genetrackR", " 9 genetrackR This package is designed to read, count, normalize, and visualize RNA-seq data at the gene level. It takes BAM files as input and leverages Bioconductor tools such as GenomicAlignments, GenomicFeatures, and SummarizedExperiment for efficient processing. The package includes four core functions: - countReads() – counts reads per gene from BAM files - normalizeCounts() – normalizes count matrices using CPM or TPM - plotGeneExpression() – visualizes gene expression per gene or per sample - exportResults() – exports tables or plots as CSV/PNG files The package features a vignette explaining how to use it with example RNA-seq data. The package is hosted on GitHub and can be installed via: devtools::install_github(“wasung/genetrackR”) #Optimising Environmental monitoring is an essential part of maintaining microbiological quality control in pharmaceutical and biotechnological manufacturing:contentReferenceoaicite:4. Cleanroom studies have shown that the typical microflora found in such controlled environments originate primarily from human skin (Gram-positive cocci), with smaller contributions from environmental organisms (Gram-positive rods) and waterborne bacteria (Gram-negative rods):contentReferenceoaicite:5. Tracking these flora over time is important – shifts in the types or numbers of microbes may signal deviations from normal conditions, such as the emergence of resistant strains or issues with cleaning procedures(Sandle 2011). For instance, a five-year survey of a cell therapy production facility found that 97.8% of the isolates were Gram-positive bacteria (mostly Staphylococcus species), and no fungi were detected, indicating that personnel were the main source of contamination(Morandi et al. 2024). This underscores that human operators can be significant contributors to cleanroom contamination, and rigorous personnel hygiene and monitoring are critical. Another challenge in contamination control is determining optimal conditions for detecting a broad range of microorganisms in environmental samples. Guidelines from different authorities vary in recommended incubation times, temperatures, and media for environmental monitoring plates, and no single consensus strategy exists(Gordon et al. 2014). Studies have demonstrated that incubation at 30–35 °C on general media is ideal for recovering bacteria, whereas fungi (molds) are best recovered at cooler temperatures (20–25 °C on specialized fungal media)(Gordon et al. 2014). Using only a high-temperature incubation can severely undercount molds, even if plates are subsequently moved to a lower temperature, so an optimized two-temperature or sequential incubation strategy may be necessary to recover both bacteria and fungi effectively. In addition to environmental microbes, Mycoplasma contamination is a serious risk in cell culture and advanced therapy products. Mycoplasmas are common yet insidious contaminants that lack cell walls, making them difficult to detect and eliminate(Sandle 2022). They can alter cell physiology and growth characteristics, potentially compromising experimental results or the safety of cell therapy products. It is therefore vital to include specific screening for mycoplasma in any contamination control strategy. Modern detection methods such as polymerase chain reaction (PCR) assays have proven to be far more sensitive and rapid for mycoplasma detection than traditional culture or biochemical tests(Molla Kazemiha et al. 2014). For example, in one comparison study PCR could detect mycoplasma in ~57.5% of contaminated cell line samples, whereas an enzyme-based method detected 52.5% and culture only 40% – underscoring PCR’s superior sensitivity(Molla Kazemiha et al. 2014). Rapid methods like the MycoAlert™ enzymatic kit also outperform classic culture in speed (providing results within 20 minutes) and can serve as a convenient screening tool(Molla Kazemiha et al. 2014). In summary, optimizing contamination control strategies requires a multifaceted approach supported by data from the literature. This includes robust environmental monitoring (with appropriate incubation conditions to capture bacteria and fungi), routine trending of cleanroom flora to detect changes(Sandle 2011), strict personnel controls (since humans are a primary contamination source)(Morandi et al. 2024), and sensitive detection methods for hard-to-find contaminants like mycoplasmas[Sandle (2022)](Molla Kazemiha et al. 2014). By integrating these evidence-based practices, one can better ensure the quality and safety of products in a high-grade cleanroom or cell culture environment. "],["parameterized-covid.html", "10 Parameterized Covid 10.1 COVID-19 Trend in Netherlands (2020)", " 10 Parameterized Covid 10.1 COVID-19 Trend in Netherlands (2020) This report presents the daily number of newly reported COVID-19 cases and deaths in Netherlands for the year 2020, focusing on the months: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12. The data is sourced from the European Centre for Disease Prevention and Control (ECDC) and includes all EU/EEA countries’ daily case counts and fatalities. Summary of Selection: For Netherlands, there were a total of 795538 reported cases and 11403 deaths in the selected period (2020, months 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12). The daily trends are shown in the graphs below. Figure: Daily reported COVID-19 cases (top) and deaths (bottom) in Netherlands for 2020 (months 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12). Each point represents the report for a single day. These trends illustrate the progression of the pandemic over the selected timeframe. "],["references.html", "11 References", " 11 References Gordon, Oliver, Manfred Berchtold, Alexandra Staerk, and David Roesti. 2014. “Comparison of Different Incubation Conditions for Microbiological Environmental Monitoring.” PDA Journal of Pharmaceutical Science and Technology 68 (5): 394–406. https://doi.org/10.5731/pdajpst.2014.00994. Molla Kazemiha, Vahid, Amir Amanzadeh, Arash Memarnejadian, Shahram Azari, Mohammad Ali Shokrgozar, Reza Mahdian, and Shahin Bonakdar. 2014. “Sensitivity of Biochemical Test in Comparison with Other Methods for the Detection of Mycoplasma Contamination in Human and Animal Cell Lines Stored in the National Cell Bank of Iran.” Cytotechnology 66 (5): 861–73. https://doi.org/10.1007/s10616-013-9640-9. Morandi, Fabio, Martina Della Lastra, Roberto Bandettini, Gino Tripodi, Federico Zara, and Irma Airoldi. 2024. “Microbes Identified from Monitoring Cell Manipulations in 5-Year Life of the Cell Factory G. Gaslini.” Regenerative Therapy 27 (December): 234–43. https://doi.org/10.1016/j.reth.2024.03.028. Sandle, Tim. 2011. “A Review of Cleanroom Microflora: Types, Trends, and Patterns.” PDA Journal of Pharmaceutical Science and Technology 65 (4): 392–403. https://doi.org/10.5731/pdajpst.2011.00765. ———. 2022. “Mycoplasma And Cell Therapy Risks,” February. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
